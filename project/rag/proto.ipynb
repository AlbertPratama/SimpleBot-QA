{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import display as Markdown\n",
    "from langchain_community.document_loaders import TextLoader, PyPDFLoader\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "api = os.getenv('HUGGING_FACE_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': './pdf/what-is-generative-ai.pdf', 'page': 0}, page_content='January 2023\\nMcKinsey Explainers\\nWhat is generative AI?\\nGenerative artificial intelligence (AI) describes algorithms (such \\nas ChatGPT) that can be used to create new content, including \\naudio, code, images, text, simulations, and videos. Recent new \\nbreakthroughs in the field have the potential to drastically change \\nthe way we approach content creation.'),\n",
       " Document(metadata={'source': './pdf/what-is-generative-ai.pdf', 'page': 1}, page_content='Generative AI systems fall under the broad \\ncategory of machine learning, and here’s how one \\nsuch system—ChatGPT—describes what it can do:\\nReady to take your creativity to the next level? \\nLook no further than generative AI! This nifty form \\nof machine learning allows computers to generate \\nall sorts of new and exciting content, from music \\nand art to entire virtual worlds. And it’s not just for \\nfun—generative AI has plenty of practical uses too, \\nlike creating new product designs and optimizing \\nbusiness processes. So why wait? Unleash the \\npower of generative AI and see what amazing \\ncreations you can come up with!\\nDid anything in that paragraph seem off to you? \\nMaybe not. The grammar is perfect, the tone works, \\nand the narrative flows.\\nWhat are ChatGPT and DALL-E?\\nThat’s why ChatGPT—the GPT stands for generative \\npretrained transformer—is receiving so much \\nattention right now. It’s a free chatbot that can \\ngenerate an answer to almost any question it’s \\nasked. Developed by OpenAI, and released for \\ntesting to the general public in November 2022, it’s \\nalready considered the best AI chatbot ever. And it’s \\npopular too: over a million people signed up to use it \\nin just five days. Starry-eyed fans posted examples \\nof the chatbot producing computer code, college-\\nlevel essays, poems, and even halfway-decent \\njokes. Others, among the wide range of people \\nwho earn their living by creating content, from \\nadvertising copywriters to tenured professors, are \\nquaking in their boots.\\nWhile many have reacted to ChatGPT (and AI and \\nmachine learning more broadly) with fear, machine \\nlearning clearly has the potential for good. In the \\nyears since its wide deployment, machine learning \\nhas demonstrated impact in a number of industries, \\naccomplishing things like medical imaging analysis \\nand high-resolution weather forecasts. A 2022 \\nMcKinsey survey shows that AI adoption has \\nmore than doubled over the past five years, and \\ninvestment in AI is increasing apace. It’s clear that \\ngenerative AI tools like ChatGPT and DALL -E (a \\ntool for AI-generated art) have the potential to \\nchange how a range of jobs are performed. The full \\nscope of that impact, though, is still unknown—as \\nare the risks. But there are some questions we can \\nanswer—like how generative AI models are built, \\nwhat kinds of problems they are best suited to \\nsolve, and how they fit into the broader category of \\nmachine learning. Read on to get the download.\\nWhat’s the difference between machine \\nlearning and artificial intelligence?\\nArtificial intelligence is pretty much just what it \\nsounds like—the practice of getting machines to \\nmimic human intelligence to perform tasks. You’ve \\nprobably interacted with AI even if you don’t realize \\nit—voice assistants like Siri and Alexa are founded \\non AI technology, as are customer service chatbots \\nthat pop up to help you navigate websites.\\nMachine learning is a type of artificial intelligence. \\nThrough machine learning, practitioners develop \\nartificial intelligence through models that can \\n“learn” from data patterns without human direction. \\nThe unmanageably huge volume and complexity \\nof data (unmanageable by humans, anyway) that is \\nnow being generated has increased the potential of \\nmachine learning, as well as the need for it.\\nWhat are the main types of \\nmachine learning models?\\nMachine learning is founded on a number of building \\nblocks, starting with classical statistical techniques \\ndeveloped between the 18th and 20th centuries \\nfor small data sets. In the 1930s and 1940s, the \\npioneers of computing—including theoretical \\nmathematician Alan Turing—began working on the \\nbasic techniques for machine learning. But these \\ntechniques were limited to laboratories until the late \\n2\\nWhat is generative AI?'),\n",
       " Document(metadata={'source': './pdf/what-is-generative-ai.pdf', 'page': 2}, page_content='1970s, when scientists first developed computers \\npowerful enough to mount them.\\nUntil recently, machine learning was largely limited \\nto predictive models, used to observe and classify \\npatterns in content. For example, a classic machine \\nlearning problem is to start with an image or several \\nimages of, say, adorable cats. The program would \\nthen identify patterns among the images, and \\nthen scrutinize random images for ones that would \\nmatch the adorable cat pattern. Generative AI was \\na breakthrough. Rather than simply perceive and \\nclassify a photo of a cat, machine learning is now \\nable to create an image or text description of a cat \\non demand.\\nHow do text-based machine learning \\nmodels work? How are they trained?\\nChatGPT may be getting all the headlines now, \\nbut it’s not the first text-based machine learning \\nmodel to make a splash. OpenAI’s GPT-3 and \\nGoogle’s BERT both launched in recent years \\nto some fanfare. But before ChatGPT, which by \\nmost accounts works pretty well most of the time \\n(though it’s still being evaluated), AI chatbots didn’t \\nalways get the best reviews. GPT-3 is “by turns \\nsuper impressive and super disappointing,” said \\nNew York Times tech reporter Cade Metz in a video \\nwhere he and food writer Priya Krishna asked \\nGPT-3 to write recipes for a (rather disastrous) \\nThanksgiving dinner.\\nThe first machine learning models to work with text \\nwere trained by humans to classify various inputs \\naccording to labels set by researchers. One example \\nwould be a model trained to label social media posts \\nas either positive or negative. This type of training is \\nknown as supervised learning because a human is in \\ncharge of “teaching” the model what to do.\\nThe next generation of text-based machine learning \\nmodels rely on what’s known as self-supervised \\nlearning. This type of training involves feeding a \\nmodel a massive amount of text so it becomes able \\nto generate predictions. For example, some models \\ncan predict, based on a few words, how a sentence \\nwill end. With the right amount of sample text—say, \\na broad swath of the internet—these text models \\nbecome quite accurate. We’re seeing just how \\naccurate with the success of tools like ChatGPT.\\nWhat does it take to build \\na generative AI model?\\nBuilding a generative AI model has for the most part \\nbeen a major undertaking, to the extent that only a \\nfew well-resourced tech heavyweights have made \\nan attempt. OpenAI, the company behind ChatGPT, \\nformer GPT models, and DALL -E, has billions in \\nfunding from boldface-name donors. DeepMind \\nis a subsidiary of Alphabet, the parent company of \\nGoogle, and Meta has released its Make-A-Video \\nproduct based on generative AI. These companies \\nemploy some of the world’s best computer \\nscientists and engineers.\\nBut it’s not just talent. When you’re asking a model \\nto train using nearly the entire internet, it’s going \\nto cost you. OpenAI hasn’t released exact costs, \\nbut estimates indicate that GPT-3 was trained on \\naround 45 terabytes of text data—that’s about one \\nmillion feet of bookshelf space, or a quarter of the \\nentire Library of Congress—at an estimated cost of \\nseveral million dollars. These aren’t resources your \\ngarden-variety start-up can access.\\nWhat kinds of output can a \\ngenerative AI model produce?\\nAs you may have noticed above, outputs from \\ngenerative AI models can be indistinguishable from \\nhuman-generated content, or they can seem a \\nlittle uncanny. The results depend on the quality of \\nthe model—as we’ve seen, ChatGPT’s outputs so \\nfar appear superior to those of its predecessors—\\nand the match between the model and the use \\ncase, or input.\\n3\\nWhat is generative AI?'),\n",
       " Document(metadata={'source': './pdf/what-is-generative-ai.pdf', 'page': 3}, page_content='ChatGPT can produce what one commentator \\ncalled a “solid A-” essay comparing theories of \\nnationalism from Benedict Anderson and Ernest \\nGellner—in ten seconds. It also produced an already \\nfamous passage describing how to remove a peanut \\nbutter sandwich from a VCR in the style of the King \\nJames Bible. AI-generated art models like DALL -E \\n(its name a mash-up of the surrealist artist Salvador \\nDalí and the lovable Pixar robot WALL -E) can create \\nstrange, beautiful images on demand, like a Raphael \\npainting of a Madonna and child, eating pizza. Other \\ngenerative AI models can produce code, video, \\naudio, or business simulations.\\nBut the outputs aren’t always accurate—or \\nappropriate. When Priya Krishna asked DALL -E \\n2 to come up with an image for Thanksgiving \\ndinner, it produced a scene where the turkey was \\ngarnished with whole limes, set next to a bowl \\nof what appeared to be guacamole. For its part, \\nChatGPT seems to have trouble counting, or solving \\nbasic algebra problems—or, indeed, overcoming the \\nsexist and racist bias that lurks in the undercurrents \\nof the internet and society more broadly.\\nGenerative AI outputs are carefully calibrated \\ncombinations of the data used to train the \\nalgorithms. Because the amount of data used to \\ntrain these algorithms is so incredibly massive—as \\nnoted, GPT-3 was trained on 45 terabytes of text \\ndata—the models can appear to be “creative” \\nwhen producing outputs. What’s more, the models \\nusually have random elements, which means they \\ncan produce a variety of outputs from one input \\nrequest—making them seem even more lifelike.\\nWhat kinds of problems can a \\ngenerative AI model solve?\\nYou’ve probably seen that generative AI tools \\n(toys?) like ChatGPT can generate endless hours \\nof entertainment. The opportunity is clear for \\nbusinesses as well. Generative AI tools can produce \\na wide variety of credible writing in seconds, then \\nrespond to criticism to make the writing more fit for \\npurpose. This has implications for a wide variety of \\nindustries, from IT and software organizations that \\ncan benefit from the instantaneous, largely correct \\ncode generated by AI models to organizations in \\nneed of marketing copy. In short, any organization \\nthat needs to produce clear written materials \\npotentially stands to benefit. Organizations can \\nalso use generative AI to create more technical \\nmaterials, such as higher-resolution versions of \\nmedical images. And with the time and resources \\nsaved here, organizations can pursue new business \\nopportunities and the chance to create more value.\\nWe’ve seen that developing a generative AI model is \\nso resource intensive that it is out of the question for \\nall but the biggest and best-resourced companies. \\nCompanies looking to put generative AI to work \\nhave the option to either use generative AI out of the \\nbox, or fine-tune them to perform a specific task. If \\nyou need to prepare slides according to a specific \\nstyle, for example, you could ask the model to \\n“learn” how headlines are normally written based on \\nthe data in the slides, then feed it slide data and ask \\nit to write appropriate headlines.\\nWhat are the limitations of \\nAI models? How can these \\npotentially be overcome?\\nSince they are so new, we have yet to see the long-\\ntail effect of generative AI models. This means there \\nare some inherent risks involved in using them—\\nsome known and some unknown.\\nThe outputs generative AI models produce may \\noften sound extremely convincing. This is by design. \\nBut sometimes the information they generate is just \\nplain wrong. Worse, sometimes it’s biased (because \\nit’s built on the gender, racial, and myriad other \\nbiases of the internet and society more generally) \\nand can be manipulated to enable unethical or \\ncriminal activity. For example, ChatGPT won’t give \\nyou instructions on how to hotwire a car, but if \\nyou say you need to hotwire a car to save a baby, \\nthe algorithm is happy to comply. Organizations \\nthat rely on generative AI models should reckon \\nwith reputational and legal risks involved in \\nunintentionally publishing biased, offensive, or \\ncopyrighted content.\\n4\\nWhat is generative AI?'),\n",
       " Document(metadata={'source': './pdf/what-is-generative-ai.pdf', 'page': 4}, page_content='Designed by McKinsey Global Publishing\\nCopyright © 2023 McKinsey & Company. All rights reserved.\\nThese risks can be mitigated, however, in a few \\nways. For one, it’s crucial to carefully select the \\ninitial data used to train these models to avoid \\nincluding toxic or biased content. Next, rather \\nthan employing an off-the-shelf generative AI \\nmodel, organizations could consider using smaller, \\nspecialized models. Organizations with more \\nresources could also customize a general model \\nbased on their own data to fit their needs and \\nminimize biases. Organizations should also keep a \\nhuman in the loop (that is, to make sure a real human \\nchecks the output of a generative AI model before it \\nis published or used) and avoid using generative AI \\nmodels for critical decisions, such as those involving \\nsignificant resources or human welfare.\\nIt can’t be emphasized enough that this is a new \\nfield. The landscape of risks and opportunities is \\nlikely to change rapidly in coming weeks, months, \\nand years. New use cases are being tested \\nmonthly, and new models are likely to be developed \\nin the coming years. As generative AI becomes \\nincreasingly, and seamlessly, incorporated into \\nbusiness, society, and our personal lives, we \\ncan also expect a new regulatory climate to take \\nshape. As organizations begin experimenting—and \\ncreating value—with these tools, leaders will do well \\nto keep a finger on the pulse of regulation and risk.\\nArticles referenced include:\\n — “The state of AI in 2022—and a half decade in \\nreview,” December 6, 2022, Michael Chui, Bryce \\nHall, Helen Mayhew, and Alex Singla\\n — “McKinsey Technology Trends Outlook 2022,” \\nAugust 24, 2022, Michael Chui, Roger Roberts, \\nand Lareina Yee \\n — “An executive’s guide to AI,” 2020, Michael Chui, \\nVishnu Kamalnath, and Brian McCarthy\\n — “What AI can and can’t do (yet) for your \\nbusiness,” January 11, 2018, Michael Chui, \\nJames Manyika, and Mehdi Miremadi\\nScan • Download • Personalize\\nFind more content like this on the \\nMcKinsey Insights App\\n5\\nWhat is generative AI?')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = PyPDFLoader('./pdf/what-is-generative-ai.pdf')\n",
    "pdf_file = loader.load()\n",
    "pdf_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_split = RecursiveCharacterTextSplitter(chunk_size=500,\n",
    "                                            chunk_overlap=100)\n",
    "docs = text_split.split_documents(pdf_file)\n",
    "docs = docs[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "API_URL = \"https://api-inference.huggingface.co/models/sentence-transformers/all-MiniLM-L6-v2\"\n",
    "headers = {\"Authorization\": f\"Bearer {api}\"}\n",
    "\n",
    "\n",
    "def query(text):\n",
    "  payload = {\"inputs\": text}\n",
    "  responnse = requests.post(API_URL, headers=headers, json=payload)\n",
    "  return responnse.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error from API: ['Field required: received `source_sentence` in `parameters`', 'Field required: received `sentences` in `parameters`']\n",
      "Error from API: ['Field required: received `source_sentence` in `parameters`', 'Field required: received `sentences` in `parameters`']\n",
      "Error from API: ['Field required: received `source_sentence` in `parameters`', 'Field required: received `sentences` in `parameters`']\n"
     ]
    }
   ],
   "source": [
    "def get_embedding(text):\n",
    "    # Memastikan bahwa input adalah string\n",
    "    if not isinstance(text, str):\n",
    "        print(f\"Invalid input: Expected string, but got {type(text)}\")\n",
    "        return None\n",
    "\n",
    "    # Batas panjang teks yang direkomendasikan (opsional, tergantung kebutuhan)\n",
    "    max_length = 512  # Misalnya, panjang maksimum bisa disesuaikan\n",
    "    if len(text) > max_length:\n",
    "        text = text[:max_length]  # Potong teks jika terlalu panjang\n",
    "\n",
    "    # Mengirimkan teks langsung tanpa 'source_sentence' atau 'sentences'\n",
    "    payload = {\"inputs\": text}\n",
    "    output = query(payload)\n",
    "\n",
    "    # Cek apakah output mengandung error\n",
    "    if 'error' in output:\n",
    "        print(f\"Error from API: {output['error']}\")\n",
    "        return None\n",
    "\n",
    "    # Cek apakah output adalah list angka (embedding)\n",
    "    if isinstance(output, list) and all(isinstance(i, float) for i in output):\n",
    "        return output  # Mengembalikan embedding mentah\n",
    "\n",
    "    print('Unexpected format:', output)\n",
    "    return None\n",
    "\n",
    "\n",
    "# Proses embedding untuk setiap dokumen\n",
    "all_embeddings = []\n",
    "for document in docs:\n",
    "    text = document.page_content.strip()  # Menghapus karakter kosong di awal/akhir\n",
    "    embedding = get_embedding(text)\n",
    "\n",
    "    if embedding is not None:\n",
    "        all_embeddings.append(embedding)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
